{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d6d1b75-4696-4f58-888c-119088702383",
   "metadata": {},
   "source": [
    "## 1.1. Poisonous Mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bfd977-11b8-421e-92b6-19e9abb97553",
   "metadata": {},
   "source": [
    "#### 1.1.1. Show the confusion matrices for models M1 and M2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618bb031-2437-4a96-ad4b-22549c451ed4",
   "metadata": {},
   "source": [
    "| | **Predicted (M1)** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "| | Poisonous | Edible | Total |\n",
    "|**Actual**| 3 | 0 | Negative: 3 |\n",
    "| | 3 | 4 | Positive: 7 | \n",
    "| | 6 | 4 | Total: 10 |\n",
    "\n",
    "| | **Predicted (M2)** | | |\n",
    "| -------- | ------------: | ------:| ----:|\n",
    "| | Poisonous | Edible | Total |\n",
    "|**Actual**| 2 | 1 | Negative: 3 |\n",
    "| | 0 | 7 | Positive: 7 |\n",
    "| | 2 | 8 | Total: 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81229661-9006-4717-a83c-af8e2545bf54",
   "metadata": {},
   "source": [
    "#### 1.1.2. Compute accuracy, precision, recall for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a9e98a-a11e-451b-bb3f-06e957595db6",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN)/(TP+TN+FP+FN)  \n",
    "Precision = TP/(TP+FP)  \n",
    "Recall = TP/(TP+FN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "888925f3-c45c-4fac-ae46-e56452c68d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Accuracy: 0.7\n",
      "Precision: 1.0\n",
      "Recall: 0.5714285714285714\n",
      "\n",
      "Model 2\n",
      "Accuracy: 0.9\n",
      "Precision: 0.875\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc_m1 = (4 + 3)/(4 + 3 + 0 + 3)\n",
    "pre_m1 = 4/(4 + 0)\n",
    "rec_m1 = 4/(4 + 3)\n",
    "\n",
    "print(\"Model 1\")\n",
    "print(f\"Accuracy: {acc_m1}\")\n",
    "print(f\"Precision: {pre_m1}\")\n",
    "print(f\"Recall: {rec_m1}\")\n",
    "\n",
    "acc_m2 = (7 + 2)/(7 + 2 + 1 + 0)\n",
    "pre_m2 = 7/(7 + 1)\n",
    "rec_m2 = 7/(7 + 0)\n",
    "\n",
    "print(\"\\nModel 2\")\n",
    "print(f\"Accuracy: {acc_m2}\")\n",
    "print(f\"Precision: {pre_m2}\")\n",
    "print(f\"Recall: {rec_m2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a97cc6-b532-48f1-9fcb-63aebcfb9673",
   "metadata": {},
   "source": [
    "#### 3. Prof. Joffe wants to get the app out tomorrow. Which model, M1 or M2 will you recommend him to use? Explain your reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68cbf24-8f09-483c-8954-e22efb9eb120",
   "metadata": {},
   "source": [
    "I would recommend Model 2, which has a higher accuracy, which means 90% of the predictions turned out to be correct. It has a slightly lower precision, which is how much of the predicted positive turned out to be correct, which wouldn't be too much of a worry because model 2 has a higher accuracy. Finally Model 2 has a higher recall, which meant that it got 100% of the actual positives correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566afa07-bbba-4386-b2e4-f258c202f984",
   "metadata": {},
   "source": [
    "## 1.2. Defendants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00309e1-ab16-4543-8ade-db55cde3d5d9",
   "metadata": {},
   "source": [
    "#### 1.2.1 Show the confusion matrices for M3 and M4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cf836-d630-48f2-84e8-d4b598b76d8f",
   "metadata": {},
   "source": [
    "| | **Predicted (M1)** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "| | Guilty | Innocent | Total |\n",
    "|**Actual**| 4 | 1 | Negative: 5 |\n",
    "| | 2 | 3 | Positive: 5 | \n",
    "| | 6 | 4 | Total: 10 |\n",
    "\n",
    "| | **Predicted (M2)** | | |\n",
    "| -------- | ------------: | ------:| ----:|\n",
    "| | Guilty | Innocent | Total |\n",
    "|**Actual**| 2 | 3 | Negative: 5|\n",
    "| | 0 | 5 | Positive: 5|\n",
    "| | 2 | 8 | Total: 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf699d-4f54-493b-b4b0-f828bdb17ac0",
   "metadata": {},
   "source": [
    "#### 1.2.2. Compute accuracy, precision, recall for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0da82b-3269-4034-9238-9a9f7e4d92c2",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN)/(TP+TN+FP+FN)  \n",
    "Precision = TP/(TP+FP)  \n",
    "Recall = TP/(TP+FN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90526c1-9e98-4d7e-bb02-951ba71763bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Accuracy: 0.7\n",
      "Precision: 0.75\n",
      "Recall: 0.6\n",
      "\n",
      "Model 2\n",
      "Accuracy: 0.7\n",
      "Precision: 0.625\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "acc_m1 = (3 + 4)/(10)\n",
    "pre_m1 = 3/(3 + 1)\n",
    "rec_m1 = 3/(3 + 2)\n",
    "\n",
    "print(\"Model 1\")\n",
    "print(f\"Accuracy: {acc_m1}\")\n",
    "print(f\"Precision: {pre_m1}\")\n",
    "print(f\"Recall: {rec_m1}\")\n",
    "\n",
    "acc_m2 = (5 + 2)/(10)\n",
    "pre_m2 = 5/(5 + 3)\n",
    "rec_m2 = 5/(5 + 0)\n",
    "\n",
    "print(\"\\nModel 2\")\n",
    "print(f\"Accuracy: {acc_m2}\")\n",
    "print(f\"Precision: {pre_m2}\")\n",
    "print(f\"Recall: {rec_m2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e563d-4175-4e19-8234-df23f397adae",
   "metadata": {},
   "source": [
    "#### 1.2.3. Cole-Tindall wants to commission the AI system tomorrow. Which model would you recommend her to use? Explain your reasoning!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935888f7-803e-4356-ad60-5aee98f6dd40",
   "metadata": {},
   "source": [
    "I would use model 2, because it has a the same accuracy, which means they resulted in the same percentage 70% of predicting the results right. It has a lower precision, which means not all innocents it predicted turned out to be innocent. But it also has a higher recall, which meant it predicted all of the actuall innocent correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f43d4-2ae0-4134-aee1-bbc848db4e89",
   "metadata": {},
   "source": [
    "## 1.3. Defendants again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd6d1b7-6577-42b2-b4fb-663cbb6a8c26",
   "metadata": {},
   "source": [
    "#### 1.3.1. Construct the corresponding confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ced2c0-5f68-48e5-9366-d537f655b50e",
   "metadata": {},
   "source": [
    "| | **Predicted (M1)** | | |\n",
    "| -------- | ------------: | ------:| -----:|\n",
    "| | Innocent | Guilty | Total |\n",
    "|**Actual**| 3 | 2 | Negative: 5 |\n",
    "| | 1 | 4 | Positive: 5 | \n",
    "| | 3 | 6 | Total: 10 |\n",
    "\n",
    "| | **Predicted (M2)** | | |\n",
    "| -------- | ------------: | ------:| ----:|\n",
    "| | Innocent | Guilty | Total |\n",
    "|**Actual**| 5 | 0 | Negative: 5|\n",
    "| | 3 | 2 | Positive: 5|\n",
    "| | 8 | 2 | Total: 10 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90496929-de70-4623-ba94-e080e64b6de7",
   "metadata": {},
   "source": [
    "#### 1.3.2. Compute accuracy, precision, recall for both models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e781fcf-1719-4f04-a70d-1c2cf4a83337",
   "metadata": {},
   "source": [
    "Accuracy = (TP + TN)/(TP+TN+FP+FN)  \n",
    "Precision = TP/(TP+FP)  \n",
    "Recall = TP/(TP+FN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc521d3-ee58-4ea2-b557-c5d444e398dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_m1 = (4 + 3)/(10)\n",
    "pre_m1 = 4 /(4 + 2)\n",
    "rec_m1 = 4/(4 + 1)\n",
    "\n",
    "print(\"Model 1\")\n",
    "print(f\"Accuracy: {acc_m1}\")\n",
    "print(f\"Precision: {pre_m1}\")\n",
    "print(f\"Recall: {rec_m1}\")\n",
    "\n",
    "acc_m2 = (2 + 5)/(10)\n",
    "pre_m2 = 2/(5 + 3)\n",
    "rec_m2 = 5/(5 + 0)\n",
    "\n",
    "print(\"\\nModel 2\")\n",
    "print(f\"Accuracy: {acc_m2}\")\n",
    "print(f\"Precision: {pre_m2}\")\n",
    "print(f\"Recall: {rec_m2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
